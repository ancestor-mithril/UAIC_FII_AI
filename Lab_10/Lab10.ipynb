{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\GeorgeS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ii', 'ar', 'citiva', 'carui', 'noştri', 'pic', 'ai', 'oricare', 'aiba', 'tau', 'tot', 'mei', 'alt', 'cei', 'dintr', 'poate', 'toata', 'aceste', 'aici', 'altceva', 'acea', 'unul', 'numai', 'oricind', 'prin', 'o', 'tu', 'ce', 'cit', 'pana', 'altii', 'vor', 'unui', 'intre', 'noastre', 'oricat', 'aceasta', 'doi', 'el', 'acele', 't', 'celor', 'aş', 'doar', 'inainte', 'iţi', 'carora', 'mulţi', 'spate', 'mea', 'incit', 'vreun', 'sintem', 'fie', 'oricum', 'unor', 'cat', 'vom', 'atata', 'meu', 'pot', 'sa', 'undeva', 'face', 'ori', 'lui', 'altcineva', 'toate', 'se', 'totuşi', 'toţi', 'putini', 'altfel', 'alte', 'nici', 'cineva', 'iti', 'ta', 'aceea', 'deja', 'la', 'aceştia', 'aia', 'de', 'prea', 'ului', 'ele', 'zice', 'tai', 'fiecare', 'lor', 'chiar', 'mele', 'iar', 'aştia', 'ca', 'ia', 'fel', 'imi', 'cumva', 'cine', 'alti', 'abia', 'acest', 'alea', 'decit', 'au', 'tine', 'doilea', 'unuia', 'acela', 'ati', 'oricit', 'voua', 'or', 'atatia', 'i', 'caci', 'atitea', 'asa', 'noua', 'sus', 'v', 'fara', 'una', 'are', 'nu', 'eşti', 'fii', 'acestea', 'caţi', 'fata', 'deşi', 'foarte', 'dintre', 'atunci', 'il', 'astea', 'cate', 'ne', 'catva', 'citeva', 'catre', 'pentru', 'acestui', 'eu', 'sint', 'apoi', 'unii', 'cui', 'oricand', 'tocmai', 'nou', 'unu', 'multi', 'dar', 'ceilalti', 'puţin', 'adica', 'atare', 'inapoi', 'acelasi', 'sati', 'avem', 'ea', 'treilea', 'orice', 'ul', 'sami', 'patra', 'uneia', 'tuturor', 'fiţi', 'voastre', 'voştri', 'totusi', 'ceva', 'acestia', 'carei', 'caruia', 'unele', 'cam', 'treia', 'citva', 'ciţi', 'cite', 'aceeasi', 'suntem', 'deasupra', 'mult', 'linga', 'acestei', 'oriunde', 'e', 'fiu', 'pina', 'maine', 'multe', 'ci', 'al', 'oricine', 'inca', 'un', 'va', 'acelea', 'anume', 'sub', 'data', 'totul', 'pai', 'li', 'zi', 'mereu', 'atit', 'cele', 'ni', 'din', 'nostru', 'noi', 'unde', 'ma', 'te', 'unei', 'am', 'altul', 'cind', 'careia', 'puţina', 'm', 'mine', 'vreo', 'ceea', 'alta', 'niste', 'langa', 'primul', 'intr', 'acesta', 'asupra', 'sale', 'miine', 'uneori', 'daca', 'vi', 'ţie', 'tale', 'as', 'deci', 'pe', 'sunteţi', 'care', 'patru', 'dupa', 'nostri', 'astfel', 'nimeni', 'isi', 'aţi', 'u', 'despre', 'atatea', 'acei', 'a', 'unora', 'voi', 'voastra', 'fost', 'mai', 'cand', 'asta', 'nimic', 'atitia', 'mie', 'doua', 'cel', 'multa', 'este', 'ti', 'fi', 'cita', 'in', 'ţi', 'noastra', 'dat', 'desi', 'era', 'trei', 'şi', 'mod', 'ei', 'atat', 'parca', 'printr', 'atita', 'prima', 'cu', 'sai', 'cea', 'si', 'vostru', 'aceşti', 'insa', 'avea', 'sunt', 'sau', 'le', 'peste', 'toti', 'nişte', 'aceia', 'spre', 'drept', 'cum', 'ale', 'aveţi', 'citi', 'mi', 'ba', 'acel', 'fim', 'eram', 'da', 'dau', 'caror', 'avut', 'ala'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "stopw = stopwords.words('romanian')\n",
    "for i in range(len(stopw)):\n",
    "    stopw[i] = stopw[i].replace('ă','a').replace('â','a').replace('ș','s').replace('ț','t').replace('î','i').replace('-','')\n",
    "\n",
    "stopw = set(stopw)\n",
    "\n",
    "print(stopw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# file_name = \"eminescu\"\n",
    "file_name = \"bacovia\"\n",
    "\n",
    "f = open(\"{}.txt\".format(file_name),'r')\n",
    "text = f.read()\n",
    "f.close()\n",
    "\n",
    "text = re.sub(r\"[',.;\\\"!?]+\", '', text.lower())\n",
    "text = re.split(r'\\W+',text)\n",
    "\n",
    "text_sw = []\n",
    "\n",
    "for word in text: \n",
    "    if word not in stopw:\n",
    "        text_sw.append(word)\n",
    "\n",
    "word_dict = {}\n",
    "\n",
    "nr_words = 0\n",
    "for word in text_sw:\n",
    "    if len(word) >= 3:\n",
    "        nr_words +=1\n",
    "        if word not in word_dict.keys():\n",
    "            word_dict[word] = 1\n",
    "        else:\n",
    "            word_dict[word] += 1\n",
    "\n",
    "for key, value in word_dict.items():\n",
    "    word_dict[key] = value * 1000000 / nr_words\n",
    "\n",
    "g = open('{}.json'.format(file_name),'w')\n",
    "json.dump(word_dict, g, indent=4)\n",
    "g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scor: 627642.0406759409\n",
      "Medie: 42.74908327720617\n"
     ]
    }
   ],
   "source": [
    "eminescu = json.load(open(\"eminescu.json\", \"r\"))\n",
    "bacovia = json.load(open(\"bacovia.json\", \"r\"))\n",
    "# eminescu\n",
    "# bacovia\n",
    "\n",
    "scor = 0\n",
    "for i in eminescu.keys():\n",
    "    if i in bacovia.keys():\n",
    "        scor += abs(eminescu[i] - bacovia[i])\n",
    "\n",
    "print(f\"Scor: {scor}\")\n",
    "print(f\"Medie: {scor / len(eminescu.keys())}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
