{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.5.zip (1.4 MB)\n",
      "Requirement already satisfied: click in c:\\users\\georges\\.conda\\envs\\nnproject\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.0.0-py3-none-any.whl (302 kB)\n",
      "Collecting regex\n",
      "  Downloading regex-2020.11.13-cp37-cp37m-win_amd64.whl (269 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.54.1-py2.py3-none-any.whl (69 kB)\n",
      "Building wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py): started\n",
      "  Building wheel for nltk (setup.py): finished with status 'done'\n",
      "  Created wheel for nltk: filename=nltk-3.5-py3-none-any.whl size=1434677 sha256=80291f970d03aa6a80226b6373236346cbf42e9a549b63abfe1ad81cab7a9a36\n",
      "  Stored in directory: c:\\users\\georges\\appdata\\local\\pip\\cache\\wheels\\45\\6c\\46\\a1865e7ba706b3817f5d1b2ff7ce8996aabdd0d03d47ba0266\n",
      "Successfully built nltk\n",
      "Installing collected packages: tqdm, regex, joblib, nltk\n",
      "Successfully installed joblib-1.0.0 nltk-3.5 regex-2020.11.13 tqdm-4.54.1\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citirea textului din fisier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"input.txt\", \"r\") as fd:\n",
    "    input_text = fd.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Preprocesarea textului"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impartirea pe propozitii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\GeorgeS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "sentences = nltk.sent_tokenize(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lorem Ipsum is simply dummy text of the printing and typesetting industry.',\n",
       " \"Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book.\",\n",
       " 'It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged.',\n",
       " 'It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizarea si eliminarea stopwords-urilor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "word_set = set()\n",
    "s = []\n",
    "for i in sentences:\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \",  i.lower())\n",
    "    y = [x for x in nltk.word_tokenize(sentence) if x not in stopwords.words('english')]\n",
    "    s.append(y)\n",
    "    word_set.update(y)\n",
    "words_in_sentences = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['lorem',\n",
       "  'ipsum',\n",
       "  'simply',\n",
       "  'dummy',\n",
       "  'text',\n",
       "  'printing',\n",
       "  'typesetting',\n",
       "  'industry'],\n",
       " ['lorem',\n",
       "  'ipsum',\n",
       "  'industry',\n",
       "  'standard',\n",
       "  'dummy',\n",
       "  'text',\n",
       "  'ever',\n",
       "  'since',\n",
       "  'unknown',\n",
       "  'printer',\n",
       "  'took',\n",
       "  'galley',\n",
       "  'type',\n",
       "  'scrambled',\n",
       "  'make',\n",
       "  'type',\n",
       "  'specimen',\n",
       "  'book'],\n",
       " ['survived',\n",
       "  'five',\n",
       "  'centuries',\n",
       "  'also',\n",
       "  'leap',\n",
       "  'electronic',\n",
       "  'typesetting',\n",
       "  'remaining',\n",
       "  'essentially',\n",
       "  'unchanged'],\n",
       " ['popularised',\n",
       "  'release',\n",
       "  'letraset',\n",
       "  'sheets',\n",
       "  'containing',\n",
       "  'lorem',\n",
       "  'ipsum',\n",
       "  'passages',\n",
       "  'recently',\n",
       "  'desktop',\n",
       "  'publishing',\n",
       "  'software',\n",
       "  'like',\n",
       "  'aldus',\n",
       "  'pagemaker',\n",
       "  'including',\n",
       "  'versions',\n",
       "  'lorem',\n",
       "  'ipsum']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_in_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aldus',\n",
       " 'also',\n",
       " 'book',\n",
       " 'centuries',\n",
       " 'containing',\n",
       " 'desktop',\n",
       " 'dummy',\n",
       " 'electronic',\n",
       " 'essentially',\n",
       " 'ever',\n",
       " 'five',\n",
       " 'galley',\n",
       " 'including',\n",
       " 'industry',\n",
       " 'ipsum',\n",
       " 'leap',\n",
       " 'letraset',\n",
       " 'like',\n",
       " 'lorem',\n",
       " 'make',\n",
       " 'pagemaker',\n",
       " 'passages',\n",
       " 'popularised',\n",
       " 'printer',\n",
       " 'printing',\n",
       " 'publishing',\n",
       " 'recently',\n",
       " 'release',\n",
       " 'remaining',\n",
       " 'scrambled',\n",
       " 'sheets',\n",
       " 'simply',\n",
       " 'since',\n",
       " 'software',\n",
       " 'specimen',\n",
       " 'standard',\n",
       " 'survived',\n",
       " 'text',\n",
       " 'took',\n",
       " 'type',\n",
       " 'typesetting',\n",
       " 'unchanged',\n",
       " 'unknown',\n",
       " 'versions'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generarea datelor de antrenare: vectori one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "word_set = list(word_set)\n",
    "word_indices = np.array([x for x in range(len(word_set))])\n",
    "\n",
    "one_hot_vectors = np.zeros((word_indices.size, word_indices.max() + 1))\n",
    "one_hot_vectors[np.arange(word_indices.size),word_indices] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_vectors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
